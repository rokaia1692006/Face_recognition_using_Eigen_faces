{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae776f29",
   "metadata": {},
   "source": [
    "#IMPORTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf292df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as scikit_learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.CascadeClassifier(cv2.data.haarcascades+\"haarcascade_frontalface_default.xml\") #facial detection model\n",
    "person = \"rokaia\" #name of person\n",
    "path = os.path.join(\"dataset\",person) # path to person dataset file\n",
    "inf=sys.maxsize\n",
    "x=0\n",
    "\n",
    "if not os.path.exists(path):# if file doesn't exist\n",
    "    os.mkdir(path) #create file\n",
    "else:    \n",
    "    print(\"Directory \" , path ,  \" exists\") #if exists\n",
    "\n",
    "video = cv2.VideoCapture(0) #open camera\n",
    "if not video.isOpened(): #not opened\n",
    "    print(\"ERROR: Unable to access the camera.\")\n",
    "    exit() #close program\n",
    "NofPhotos = 50 #number of photos per file\n",
    "counter = 0 #flag\n",
    "while True: #infinite loop\n",
    "        ret, frame = video.read() #frame from camera\n",
    "        if not ret: #no frame\n",
    "            print(\"Camera Error\")\n",
    "            break #exit loop\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  #frame to gray\n",
    "\n",
    "        faces = detector.detectMultiScale( #faces per frame\n",
    "         frame, scaleFactor=1.2, minNeighbors=5)\n",
    "        \n",
    "        for face in faces:\n",
    "            \n",
    "                x, y, w, h = face\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,255),thickness=3) #rectangle around face\n",
    "                sub_face = frame[y:y+h,x:x+w] #save face in variable\n",
    "                name = os.path.join(path, f\"{person}_{random.randint(x,inf)}.jpg\") #path of image (random)\n",
    "                cv2.imwrite(name, sub_face) #write the image \n",
    "                cv2.putText(frame,f\"{counter}/{NofPhotos}\",(50,50),cv2.FONT_HERSHEY_SIMPLEX, #add number of photos taken\n",
    "                            1,(0,0,255),2,cv2.LINE_AA)\n",
    "                counter+=1\n",
    "                if counter>=NofPhotos: #if counter = number of phots\n",
    "                      cv2.putText(frame,\"DONE\",(50,50),cv2.FONT_HERSHEY_SIMPLEX, # add text done\n",
    "                            1,(0,0,255),2,cv2.LINE_AA)\n",
    "                      #print(\"DONE\")\n",
    "                      cv2.waitKey(2000) #wait to see done\n",
    "                      break #break out of loop\n",
    "                            \n",
    "        cv2.imshow(\"datasetCreate\",frame) #show frame in a window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('e') or counter>=NofPhotos : #if  'e' is pressed break from loop\n",
    "                break\n",
    "#close camera and close window\n",
    "video.release() \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.path.join(\"dataset\")\n",
    "for file in os.listdir(files): #open each file in directory\n",
    "    imgpath = os.path.join(files,file) #save path of each person's file\n",
    "    print(imgpath)\n",
    "    #print(file)\n",
    "    if os.path.isdir(file):# if file is a directory\n",
    "        for images in os.listdir(file):# images in each file\n",
    "            path = os.path.join(imgpath,images) # path of each image\n",
    "            image =  cv2.imread(path) #save image in variable\n",
    "            image = cv2.resize(image,(100,100)) #resize image 100px,100px\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) #gray\n",
    "            cv2.imwrite(path,image) #save image\n",
    "            print(imgpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7aef56",
   "metadata": {},
   "source": [
    "PREPARING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c019dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathImages = os.path.join(\"dataset\")\n",
    "ids = []\n",
    "images = []\n",
    "for filename in os.listdir(pathImages):\n",
    "    folderpath = os.path.join(pathImages,filename)\n",
    "    if os.path.isdir(folderpath):\n",
    "      for imgs in os.listdir(folderpath):\n",
    "                  imgpath = os.path.join(folderpath , imgs)\n",
    "                  img =  cv2.imread(imgpath)\n",
    "                  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "                  img = cv2.resize(img,(100,100))\n",
    "                  images.append(img)\n",
    "                  ids.append(filename)\n",
    "\n",
    "both = list(zip(ids,images)) #zip image and ids into a list\n",
    "random.shuffle(both) #shuufle data so model doesn't learn unwanted patterns\n",
    "ids, images = zip(*both)#put data back in ids and images\n",
    "images = np.array(images) #numpy array \n",
    "ids = np.array(ids) #numpy array\n",
    "ids\n",
    "#show 5 images from the images in the array\n",
    "plt.figure(figsize=(100,100)) \n",
    "for i in range(min(10,len(images))):\n",
    "       plt.subplot(1,10,i+1)\n",
    "       #plt.gray()\n",
    "       plt.imshow(images[i])\n",
    "       plt.axis('off')\n",
    "       plt.title(f\"ID{ids[i]}\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(len(images))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5816a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathImages = os.path.join(\"dataset\")\n",
    "ids = []\n",
    "images = []\n",
    "for filename in os.listdir(pathImages):\n",
    "    folderpath = os.path.join(pathImages,filename)\n",
    "    if os.path.isdir(folderpath):\n",
    "      for imgs in os.listdir(folderpath):\n",
    "                  #just making sure\n",
    "                  imgpath = os.path.join(folderpath , imgs)\n",
    "                  img =  cv2.imread(imgpath)\n",
    "                  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "                  img = cv2.resize(img,(100,100))\n",
    "                  print(f\"loading image{imgpath}\")\n",
    "                  ############################\n",
    "                  flatimg = img.flatten() #Turns image into a vector <10000,>\n",
    "                  #print(flatimg.shape) #print shape of image if correct <10000,>\n",
    "                  images.append(flatimg) # append vector in images array\n",
    "                  ids.append(filename) #id = name of person\n",
    "\n",
    "both = list(zip(ids,images))#zip data \n",
    "random.shuffle(both) #shuufle \n",
    "ids, images = zip(*both) #unzip\n",
    "images = np.array(images) #numpy array \n",
    "#print(images.shape) #print shape\n",
    "ids = np.array(ids)\n",
    "#print(ids.shape)\n",
    "ids\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046daa73",
   "metadata": {},
   "source": [
    "TRANING CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1cc28ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5e8ad",
   "metadata": {},
   "source": [
    "FINDING AND VISUALIZING EIGEN Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find eigen faces \n",
    "eigen_faces = []\n",
    "\n",
    "scaler =StandardScaler()\n",
    " #calculates the meanand the standard deviation\n",
    " #removes mean and devides by the standard deviation\n",
    " \n",
    "standard = scaler.fit_transform(images)\n",
    "n_components = 90#principal components from dataset\n",
    "#pca with number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "#fit pcs to the standard data\n",
    "pca.fit(standard)\n",
    "#transform data\n",
    "trans_data = pca.transform(standard)\n",
    "#find eigen faces\n",
    "for i in range(n_components):\n",
    "    eigen_face = pca.components_[i]\n",
    "    eigen_faces.append(eigen_face)\n",
    "#print eigen faces\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(min(10,n_components)):\n",
    "      plt.subplot(2,5,i+1)\n",
    "      ef = eigen_faces[i].reshape(100,100)\n",
    "      plt.imshow(ef,'gray')\n",
    "      plt.axis('off')\n",
    "     \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training classifier SVM\n",
    "import joblib\n",
    "from sklearn.svm import SVC # multiple\n",
    "#train 80% test 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(standard, ids, test_size=0.2, random_state=42) \n",
    "svm_classifier = SVC(kernel=\"rbf\", gamma='scale', probability=True,verbose = True)\n",
    "svm_classifier.fit(X_train, y_train) #train classifier\n",
    "joblib.dump(svm_classifier,'recognitionp2.pkl')#save model\n",
    "#check accuracy\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save scaler\n",
    "joblib.dump(scaler,'scaler.pkl')\n",
    "#save pca\n",
    "joblib.dump(pca,'pca.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df00d39",
   "metadata": {},
   "source": [
    "LIVE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#load face detection model prebuilt\n",
    "detector = cv2.CascadeClassifier(cv2.data.haarcascades+\"haarcascade_frontalface_default.xml\") \n",
    "video = cv2.VideoCapture(0)\n",
    "model = joblib.load(\"recognitionp2.pkl\") #load model\n",
    "scaler = joblib.load(\"scaler.pkl\") #load scaler\n",
    "pca = joblib.load(\"pca.pkl\") #load pca\n",
    "if not video.isOpened():\n",
    "    print(\"ERROR: Unable to access the camera.\")\n",
    "    exit()\n",
    "while True:\n",
    "        ret, frame = video.read() #get frame from camera\n",
    "        if not ret:\n",
    "            print(\"Camera Error\")\n",
    "            break\n",
    "       \n",
    "        #gray frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "        #find faces in frame\n",
    "        faces = detector.detectMultiScale(\n",
    "         gray, scaleFactor=1.2, minNeighbors=5)\n",
    "        \n",
    "        for face in faces:\n",
    "            \n",
    "                x, y, w, h = face \n",
    "                #draw rectangle around recognized faces\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,255),thickness=3)\n",
    "                sub_face = gray[y:y+h,x:x+w]\n",
    "                #image given to trained model must be in the same format as the images the model was trained on\n",
    "                sub_face = cv2.resize(sub_face, (100, 100))\n",
    "                \n",
    "                sub_face_flat = sub_face.flatten() #image into vector <10000,>\n",
    "                #standarizes the data by removing the mean face found previously\n",
    "                sub_face_flat_standard = scaler.transform([sub_face_flat]) \n",
    "                #changes dimention of the data to 100\n",
    "                sub_face_pca = pca.transform(sub_face_flat_standard)\n",
    "                #predicts the face \n",
    "                answer = model.predict(sub_face_flat_standard)[0]\n",
    "                print(answer)\n",
    "                if answer != -1: #there's a face recognized\n",
    "                    # put name of preson on the box around there face\n",
    "                    cv2.putText(frame,answer,(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                1,(0,0,255),2,cv2.LINE_AA)\n",
    "                \n",
    "        cv2.imshow(\"DEMO\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('e') :\n",
    "                break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d1986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
